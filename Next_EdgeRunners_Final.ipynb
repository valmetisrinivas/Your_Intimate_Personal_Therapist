{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 9226044,
          "sourceType": "datasetVersion",
          "datasetId": 5579934
        }
      ],
      "dockerImageVersionId": 30762,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Task.1: Synthetic Data Generation**"
      ],
      "metadata": {
        "id": "q2puJoVDfiYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "3kXXjCz1felJ",
        "execution": {
          "iopub.status.busy": "2024-08-23T06:56:09.205971Z",
          "iopub.execute_input": "2024-08-23T06:56:09.206348Z",
          "iopub.status.idle": "2024-08-23T06:56:24.511096Z",
          "shell.execute_reply.started": "2024-08-23T06:56:09.206316Z",
          "shell.execute_reply": "2024-08-23T06:56:24.509955Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import time\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "import sys\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "KIEctHCDgCqy",
        "execution": {
          "iopub.status.busy": "2024-08-23T06:56:25.774740Z",
          "iopub.execute_input": "2024-08-23T06:56:25.775302Z",
          "iopub.status.idle": "2024-08-23T06:56:25.780620Z",
          "shell.execute_reply.started": "2024-08-23T06:56:25.775241Z",
          "shell.execute_reply": "2024-08-23T06:56:25.779328Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_environment():\n",
        "    if 'google.colab' in sys.modules:\n",
        "        return 'colab'\n",
        "    elif 'notebook' in sys.modules:\n",
        "        return 'jupyter'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "env = get_environment()\n",
        "print(f\"Running in: {env}\")"
      ],
      "metadata": {
        "id": "1KJ-ddGwggxN",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if env == 'colab':\n",
        "    aim_api_key = userdata.get('AIM_API_KEY')\n",
        "elif env == 'jupyter':\n",
        "    aim_api_key = os.getenv('AIM_API_KEY')"
      ],
      "metadata": {
        "id": "kyCPLE2uggu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(columns=['Doctor', 'Patient']).to_csv(\"data_generated.csv\",index=False)"
      ],
      "metadata": {
        "id": "OecaS_v5xthD",
        "execution": {
          "iopub.status.busy": "2024-08-23T06:56:25.782930Z",
          "iopub.execute_input": "2024-08-23T06:56:25.783291Z",
          "iopub.status.idle": "2024-08-23T06:56:25.797764Z",
          "shell.execute_reply.started": "2024-08-23T06:56:25.783247Z",
          "shell.execute_reply": "2024-08-23T06:56:25.796548Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_content_1 = \"You are an expert in Cognitive Behavioural Therapy (CBT).\"\n",
        "user_content = \"\"\"Assume a setting where a Therapist in a conversation with a visitor.The visitor is mostly a patient but can be occassionally a close relative\n",
        "to the patient like like patient's father or mother as well. Generate a conversation set between the therapist and visitor, with 6 consecutive dialogues in a dictionary format,\n",
        "for example, each of the 6 dialogues should be in this format -- {\"therapist\":\"Good morning,what can I do for you?\", \"visitor\": \"I am not feeling well.\"}.\n",
        "The dialogue should be focussed around CBT and sound very natural. Ensure that each dialogue  has 'therapist' string and a corresponding 'visitor' string and is symantically and syntactically complete\".\n",
        "Also do not output metadata like \"**Dialogue 1**\". \"\"\"\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    api_key=aim_api_key,\n",
        "    base_url=\"https://api.aimlapi.com\",\n",
        ")\n",
        "\n",
        "for i in range(1000):\n",
        "  try:\n",
        "    chat_completion = client.chat.completions.create(\n",
        "      model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": system_content_1},\n",
        "          {\"role\": \"user\", \"content\": user_content},\n",
        "      ],\n",
        "      temperature=0.7,\n",
        "      max_tokens=512,\n",
        "    )\n",
        "    responses=[]\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    print(response)\n",
        "    dialogue_matches = re.findall(r'\\{.*?\\}', response, re.DOTALL)\n",
        "    for dialogue in dialogue_matches:\n",
        "        parsed_dialogue = json.loads(dialogue)\n",
        "        d = parsed_dialogue[\"therapist\"]\n",
        "        # .replace('(','').replace(')', '')\n",
        "        p = parsed_dialogue[\"visitor\"]\n",
        "        # print(d)\n",
        "        # print(p)\n",
        "        responses.append([d,p])\n",
        "    print(responses)\n",
        "    with open(\"data_generated.csv\", mode='a', newline='') as f:\n",
        "      writer = csv.writer(f)\n",
        "      for r in responses:\n",
        "        writer.writerow(r)\n",
        "\n",
        "\n",
        "  except KeyError:\n",
        "    pass\n",
        "\n",
        "  except openai.RateLimitError as e:\n",
        "    print(f\"Rate Limit reached\")\n",
        "    break"
      ],
      "metadata": {
        "id": "nrSnZ9PVgIMO",
        "execution": {
          "iopub.status.busy": "2024-08-23T06:56:45.289607Z",
          "iopub.execute_input": "2024-08-23T06:56:45.290627Z",
          "iopub.status.idle": "2024-08-23T06:57:11.519506Z",
          "shell.execute_reply.started": "2024-08-23T06:56:45.290567Z",
          "shell.execute_reply": "2024-08-23T06:57:11.518557Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df =pd.read_csv(\"data_generated.csv\").head(10)\n",
        "for i, row in df.iterrows():\n",
        "  print(f\"Obseravtion: {i}\")\n",
        "  print(df.loc[i,'Doctor'])\n",
        "  print(df.loc[i,'Patient'])\n",
        "  print('*'*50)"
      ],
      "metadata": {
        "id": "YMTewapljy7l",
        "execution": {
          "iopub.status.busy": "2024-08-23T06:57:40.226278Z",
          "iopub.execute_input": "2024-08-23T06:57:40.227283Z",
          "iopub.status.idle": "2024-08-23T06:57:40.243324Z",
          "shell.execute_reply.started": "2024-08-23T06:57:40.227240Z",
          "shell.execute_reply": "2024-08-23T06:57:40.242406Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rfmx1IKpjy5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Task.2: Fine Tuning with TinyLLAMA**"
      ],
      "metadata": {
        "id": "Jx_tNvNHfiXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T06:57:46.632001Z",
          "iopub.execute_input": "2024-08-23T06:57:46.632355Z",
          "iopub.status.idle": "2024-08-23T06:58:01.541105Z",
          "shell.execute_reply.started": "2024-08-23T06:57:46.632323Z",
          "shell.execute_reply": "2024-08-23T06:58:01.539931Z"
        },
        "trusted": true,
        "id": "dRPSsN2UZmJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install triton torch==2.3.1\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "aZ398oixkRkk",
        "execution": {
          "iopub.status.busy": "2024-08-23T06:58:01.543708Z",
          "iopub.execute_input": "2024-08-23T06:58:01.544454Z",
          "iopub.status.idle": "2024-08-23T07:01:11.597115Z",
          "shell.execute_reply.started": "2024-08-23T06:58:01.544390Z",
          "shell.execute_reply": "2024-08-23T07:01:11.595864Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# Configuration settings\n",
        "max_seq_length = 2048  # Maximum sequence length supported by the model\n",
        "dtype = None           # Set to None for auto-detection, Float16 for T4/V100, Bfloat16 for Ampere GPUs\n",
        "load_in_4bit = True    # Enable 4-bit loading for memory efficiency\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/tinyllama-bnb-4bit\",  # Model name for 4-bit precision loading\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        "    # token = \"hf_...\", # Uncomment and use if working with gated models like Meta's LLaMA-2\n",
        ")"
      ],
      "metadata": {
        "id": "YnOLAlq8l5uH",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:01:40.277630Z",
          "iopub.execute_input": "2024-08-23T07:01:40.278015Z",
          "iopub.status.idle": "2024-08-23T07:01:44.718527Z",
          "shell.execute_reply.started": "2024-08-23T07:01:40.277974Z",
          "shell.execute_reply": "2024-08-23T07:01:44.717252Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,  # LoRA rank, affects the number of trainable parameters\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                    \"gate_proj\", \"up_proj\", \"down_proj\",\"embed_tokens\", \"lm_head\",],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,  # Dropout for regularization, currently set to 0\n",
        "    bias=\"none\",     # No bias used in this configuration\n",
        "    use_gradient_checkpointing=True,  # Useful for reducing memory usage during training\n",
        "    use_rslora=False,  # Rank Stabilized LoRA, set to False in this case\n",
        "    loftq_config=None, # LoRA with Quantization, not used here\n",
        ")"
      ],
      "metadata": {
        "id": "4_NBfQMsl_T-",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:01:55.534041Z",
          "iopub.execute_input": "2024-08-23T07:01:55.534343Z",
          "iopub.status.idle": "2024-08-23T07:01:55.672420Z",
          "shell.execute_reply.started": "2024-08-23T07:01:55.534311Z",
          "shell.execute_reply": "2024-08-23T07:01:55.671180Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"data_generated.csv\")"
      ],
      "metadata": {
        "id": "OyrMXEQDmieP",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:01:57.711648Z",
          "iopub.execute_input": "2024-08-23T07:01:57.712308Z",
          "iopub.status.idle": "2024-08-23T07:01:57.718179Z",
          "shell.execute_reply.started": "2024-08-23T07:01:57.712276Z",
          "shell.execute_reply": "2024-08-23T07:01:57.717373Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T07:02:10.380938Z",
          "iopub.execute_input": "2024-08-23T07:02:10.381928Z",
          "iopub.status.idle": "2024-08-23T07:02:10.388269Z",
          "shell.execute_reply.started": "2024-08-23T07:02:10.381886Z",
          "shell.execute_reply": "2024-08-23T07:02:10.387319Z"
        },
        "trusted": true,
        "id": "PGisdT9XZmJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "instruction_text = \"\"\"You are an Expert Therapist specialized in Cognitive Behavioural Therapy (CBT).\n",
        "                      Respond to to Patient's remarks in a polite, professional, contextually meaningful and useful manner.\"\"\"\n",
        "\n",
        "data_list = data.to_dict(orient=\"records\")\n",
        "\n",
        "for entry in data_list:\n",
        "    entry[\"instruction\"] = instruction_text\n",
        "    entry[\"input\"] = entry.pop(\"Patient\")\n",
        "    entry[\"output\"] = entry.pop(\"Doctor\")\n",
        "\n",
        "with open('json_data.json', 'w') as f:\n",
        "    json.dump(data_list, f, indent=4)"
      ],
      "metadata": {
        "id": "do7_ooZ0nBIN",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:02:27.172854Z",
          "iopub.execute_input": "2024-08-23T07:02:27.173643Z",
          "iopub.status.idle": "2024-08-23T07:02:27.187959Z",
          "shell.execute_reply.started": "2024-08-23T07:02:27.173602Z",
          "shell.execute_reply": "2024-08-23T07:02:27.182175Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_json('json_data.json').head(3)"
      ],
      "metadata": {
        "id": "naYMVqfynLqn",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:02:32.307634Z",
          "iopub.execute_input": "2024-08-23T07:02:32.307955Z",
          "iopub.status.idle": "2024-08-23T07:02:32.324747Z",
          "shell.execute_reply.started": "2024-08-23T07:02:32.307921Z",
          "shell.execute_reply": "2024-08-23T07:02:32.323777Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "dataset = load_dataset(\"json\", data_files=\"json_data.json\")"
      ],
      "metadata": {
        "id": "L7pkKpfInLod",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:02:40.768225Z",
          "iopub.execute_input": "2024-08-23T07:02:40.768645Z",
          "iopub.status.idle": "2024-08-23T07:02:41.020306Z",
          "shell.execute_reply.started": "2024-08-23T07:02:40.768609Z",
          "shell.execute_reply": "2024-08-23T07:02:41.019412Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset= DatasetDict({'train': dataset['train']})\n",
        "dataset"
      ],
      "metadata": {
        "id": "6M_Ew8BTnwPx",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a prompt template\n",
        "prompt = \"\"\"Below is an instruction that describes a task, paired with an input. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "# Function to format the prompts\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "# Apply the formatting function to the dataset\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "dataset_dict = dataset['train'].train_test_split(test_size=0.3)\n",
        "\n",
        "train_dataset = dataset_dict[\"train\"]\n",
        "eval_dataset = dataset_dict[\"test\"]"
      ],
      "metadata": {
        "id": "3m--gu6sn0rm",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:11:59.568142Z",
          "iopub.execute_input": "2024-08-23T07:11:59.568967Z",
          "iopub.status.idle": "2024-08-23T07:11:59.615129Z",
          "shell.execute_reply.started": "2024-08-23T07:11:59.568924Z",
          "shell.execute_reply": "2024-08-23T07:11:59.614226Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.shape"
      ],
      "metadata": {
        "id": "47jyfy3Sn-iy",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset.shape"
      ],
      "metadata": {
        "id": "jQJ1RQ8foCcb",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:12:13.616745Z",
          "iopub.execute_input": "2024-08-23T07:12:13.617337Z",
          "iopub.status.idle": "2024-08-23T07:12:13.622677Z",
          "shell.execute_reply.started": "2024-08-23T07:12:13.617304Z",
          "shell.execute_reply": "2024-08-23T07:12:13.621679Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "pXtnbcQyoCZ_",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:03:17.351868Z",
          "iopub.execute_input": "2024-08-23T07:03:17.352769Z",
          "iopub.status.idle": "2024-08-23T07:03:31.218408Z",
          "shell.execute_reply.started": "2024-08-23T07:03:17.352718Z",
          "shell.execute_reply": "2024-08-23T07:03:31.217262Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_environment():\n",
        "    if 'google.colab' in sys.modules:\n",
        "        return 'colab'\n",
        "    elif 'notebook' in sys.modules:\n",
        "        return 'jupyter'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "env = get_environment()\n",
        "print(f\"Running in: {env}\")"
      ],
      "metadata": {
        "id": "37olsB3Zoxbz",
        "execution": {
          "iopub.status.busy": "2024-08-22T15:10:00.463009Z",
          "iopub.execute_input": "2024-08-22T15:10:00.463378Z",
          "iopub.status.idle": "2024-08-22T15:10:00.470630Z",
          "shell.execute_reply.started": "2024-08-22T15:10:00.463340Z",
          "shell.execute_reply": "2024-08-22T15:10:00.469269Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if env == 'colab':\n",
        "    wandb_api_key = userdata.get('WANDB_API_KEY')\n",
        "elif env == 'jupyter':\n",
        "    wandb_api_key = os.getenv('WAND_API_KEY')"
      ],
      "metadata": {
        "id": "aULjfPp-o4dQ",
        "execution": {
          "iopub.status.busy": "2024-08-22T15:10:00.471867Z",
          "iopub.execute_input": "2024-08-22T15:10:00.472243Z",
          "iopub.status.idle": "2024-08-22T15:10:00.490589Z",
          "shell.execute_reply.started": "2024-08-22T15:10:00.472199Z",
          "shell.execute_reply": "2024-08-22T15:10:00.489617Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# Log in to W&B - you'll be prompted to input your API key\n",
        "wandb.login(key = wandb_api_key)\n",
        "\n",
        "# Set W&B environment variables\n",
        "%env WANDB_WATCH=all\n",
        "%env WANDB_SILENT=true"
      ],
      "metadata": {
        "id": "dfLhkBDBoOpi",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:03:31.219900Z",
          "iopub.execute_input": "2024-08-23T07:03:31.220244Z",
          "iopub.status.idle": "2024-08-23T07:03:33.905623Z",
          "shell.execute_reply.started": "2024-08-23T07:03:31.220207Z",
          "shell.execute_reply": "2024-08-23T07:03:33.904682Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "from transformers.utils import logging\n",
        "import wandb\n",
        "\n",
        "logging.set_verbosity_info()\n",
        "\n",
        "# Initialize W&B\n",
        "project_name = \"tiny-llama\"\n",
        "entity = \"wandb\"\n",
        "wandb.init(project=project_name, name=\"unsloth-tiny-llama\")\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=2,           # Small batch size due to limited GPU memory\n",
        "    gradient_accumulation_steps=4,           # Accumulate gradients over 4 steps\n",
        "    evaluation_strategy=\"steps\",             # Evaluate after a certain number of steps\n",
        "    warmup_ratio=0.1,                        # Warm-up learning rate over 10% of training\n",
        "    num_train_epochs=1,                      # Number of epochs\n",
        "    learning_rate=2e-4,                      # Learning rate for the optimizer\n",
        "    fp16=not is_bfloat16_supported(),        # Use FP16 if BF16 is not supported\n",
        "    bf16=is_bfloat16_supported(),            # Use BF16 if supported (more efficient on Ampere GPUs)\n",
        "    max_steps=20,                            # Cap training at 20 steps for quick experimentation, increase or comment out as you see fit\n",
        "    logging_steps=1,                         # Log metrics every step\n",
        "    optim=\"adamw_8bit\",                      # Use 8-bit AdamW optimizer to save memory\n",
        "    weight_decay=0.1,                        # Regularization to avoid overfitting\n",
        "    lr_scheduler_type=\"linear\",              # Use linear learning rate decay\n",
        "    seed=3407,                               # Random seed for reproducibility\n",
        "    report_to=\"wandb\",                       # Enable logging to W&B\n",
        "    output_dir=\"outputs\",                    # Directory to save model outputs\n",
        ")"
      ],
      "metadata": {
        "id": "yoc69Md0pgtj",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:12:31.648172Z",
          "iopub.execute_input": "2024-08-23T07:12:31.648589Z",
          "iopub.status.idle": "2024-08-23T07:12:54.338231Z",
          "shell.execute_reply.started": "2024-08-23T07:12:31.648552Z",
          "shell.execute_reply": "2024-08-23T07:12:54.337484Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,     # Training dataset\n",
        "    eval_dataset=eval_dataset,       # Evaluation dataset\n",
        "    dataset_text_field=\"text\",               # The field containing text in the dataset\n",
        "    max_seq_length=max_seq_length,           # Max sequence length for inputs\n",
        "    dataset_num_proc=2,                      # Number of processes for dataset loading\n",
        "    packing=True,                            # Packs short sequences together to save time\n",
        "    args=training_args,                      # Training arguments defined earlier\n",
        ")"
      ],
      "metadata": {
        "id": "GqxR-OYmplH-",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:13:08.939211Z",
          "iopub.execute_input": "2024-08-23T07:13:08.939606Z",
          "iopub.status.idle": "2024-08-23T07:13:09.057120Z",
          "shell.execute_reply.started": "2024-08-23T07:13:08.939562Z",
          "shell.execute_reply": "2024-08-23T07:13:09.056172Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training the model\n",
        "trainer.train()\n",
        "\n",
        "# Finish and close the W&B session\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "jeEmhnq8poyL",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:13:13.830501Z",
          "iopub.execute_input": "2024-08-23T07:13:13.830870Z",
          "iopub.status.idle": "2024-08-23T07:14:15.000643Z",
          "shell.execute_reply.started": "2024-08-23T07:13:13.830837Z",
          "shell.execute_reply": "2024-08-23T07:14:14.999935Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T07:15:25.615331Z",
          "iopub.execute_input": "2024-08-23T07:15:25.616142Z",
          "iopub.status.idle": "2024-08-23T07:15:25.635138Z",
          "shell.execute_reply.started": "2024-08-23T07:15:25.616101Z",
          "shell.execute_reply": "2024-08-23T07:15:25.634243Z"
        },
        "trusted": true,
        "id": "mtNnWOMCZmKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model)  # Enable faster inference\n",
        "inputs = tokenizer(\n",
        "    [\n",
        "        prompt.format(\n",
        "            \"You are an Expert Therapist specialized in Cognitive Behavioural Therapy (CBT). Respond to to Patient's remarks in a polite, professional, contextually meaningful and useful manner.\",  # instruction\n",
        "            \"I am feeling tired and anxious\",  # input\n",
        "            \"\",  # output - leave this blank for generation!\n",
        "        )\n",
        "    ], return_tensors=\"pt\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
        "# print(tokenizer.decode(outputs[0]),'\\n\\n')\n",
        "chars_to_remove = re.compile('<.*?>')\n",
        "outputs = tokenizer.decode(outputs[0]).split('### Response:')[1].split('###')[0].strip()\n",
        "response = re.sub(chars_to_remove, '', outputs)\n",
        "\n",
        "print(f\"Therapist: {response}\")"
      ],
      "metadata": {
        "id": "i7E9pSWcp2mp",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:15:40.805100Z",
          "iopub.execute_input": "2024-08-23T07:15:40.805746Z",
          "iopub.status.idle": "2024-08-23T07:15:41.825610Z",
          "shell.execute_reply.started": "2024-08-23T07:15:40.805706Z",
          "shell.execute_reply": "2024-08-23T07:15:41.824729Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_environment():\n",
        "    if 'google.colab' in sys.modules:\n",
        "        return 'colab'\n",
        "    elif 'notebook' in sys.modules:\n",
        "        return 'jupyter'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "env = get_environment()\n",
        "print(f\"Running in: {env}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T07:22:38.691642Z",
          "iopub.execute_input": "2024-08-23T07:22:38.691936Z",
          "iopub.status.idle": "2024-08-23T07:22:38.697380Z",
          "shell.execute_reply.started": "2024-08-23T07:22:38.691905Z",
          "shell.execute_reply": "2024-08-23T07:22:38.696512Z"
        },
        "trusted": true,
        "id": "BxoN8JKbZmKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if env == 'colab':\n",
        "    hf_api_key = userdata.get('HF_API_KEY')\n",
        "elif env == 'jupyter':\n",
        "    hf_api_key = os.getenv('HF_API_KEY')"
      ],
      "metadata": {
        "id": "Bg3Fq8OVrGei",
        "execution": {
          "iopub.status.busy": "2024-08-22T15:12:39.683739Z",
          "iopub.execute_input": "2024-08-22T15:12:39.684170Z",
          "iopub.status.idle": "2024-08-22T15:12:39.689022Z",
          "shell.execute_reply.started": "2024-08-22T15:12:39.684128Z",
          "shell.execute_reply": "2024-08-22T15:12:39.688077Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token=hf_api_key)"
      ],
      "metadata": {
        "id": "M7vhfq3Wp37z",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:17:00.994087Z",
          "iopub.execute_input": "2024-08-23T07:17:00.994908Z",
          "iopub.status.idle": "2024-08-23T07:17:01.052517Z",
          "shell.execute_reply.started": "2024-08-23T07:17:00.994868Z",
          "shell.execute_reply": "2024-08-23T07:17:01.051624Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbZZBXOHZmKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"TinyLLAMA_VS_test\")\n",
        "tokenizer.push_to_hub(\"TinyLLAMA_VS_test\")"
      ],
      "metadata": {
        "id": "W9wHBO3lqGaa",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:17:20.552166Z",
          "iopub.execute_input": "2024-08-23T07:17:20.553231Z",
          "iopub.status.idle": "2024-08-23T07:17:28.733451Z",
          "shell.execute_reply.started": "2024-08-23T07:17:20.553174Z",
          "shell.execute_reply": "2024-08-23T07:17:28.732620Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "hf_model = FastLanguageModel.from_pretrained(\"vsrinivas/TinyLLAMA_VS_test\")\n",
        "hf_tokenizer = AutoTokenizer.from_pretrained(\"vsrinivas/TinyLLAMA_VS_test\")"
      ],
      "metadata": {
        "id": "uHn1jgZurWkA",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:18:38.445322Z",
          "iopub.execute_input": "2024-08-23T07:18:38.446380Z",
          "iopub.status.idle": "2024-08-23T07:18:51.691907Z",
          "shell.execute_reply.started": "2024-08-23T07:18:38.446327Z",
          "shell.execute_reply": "2024-08-23T07:18:51.690888Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Below is an instruction that describes a task, paired with an input. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T07:17:59.525995Z",
          "iopub.execute_input": "2024-08-23T07:17:59.526792Z",
          "iopub.status.idle": "2024-08-23T07:17:59.531180Z",
          "shell.execute_reply.started": "2024-08-23T07:17:59.526750Z",
          "shell.execute_reply": "2024-08-23T07:17:59.530157Z"
        },
        "trusted": true,
        "id": "l6pqhCuzZmKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T07:19:10.854311Z",
          "iopub.execute_input": "2024-08-23T07:19:10.855064Z",
          "iopub.status.idle": "2024-08-23T07:19:10.875372Z",
          "shell.execute_reply.started": "2024-08-23T07:19:10.855021Z",
          "shell.execute_reply": "2024-08-23T07:19:10.874410Z"
        },
        "trusted": true,
        "id": "WlQ4aUkHZmKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(hf_model[0])  # Enable faster inference\n",
        "inputs = hf_tokenizer(\n",
        "    [\n",
        "        prompt.format(\n",
        "            \"You are an Expert Therapist specialized in Cognitive Behavioural Therapy (CBT). Respond to to Patient's remarks in a polite, professional, contextually meaningful and useful manner.\",  # instruction\n",
        "            \"I am feeling tired and anxious\",  # input\n",
        "            \"\",  # output - leave this blank for generation!\n",
        "        )\n",
        "    ], return_tensors=\"pt\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = hf_model[0].generate(**inputs, max_new_tokens=64, use_cache=True)\n",
        "# print(hf_tokenizer.decode(outputs[0]),'\\n\\n')\n",
        "chars_to_remove = re.compile('<.*?>')\n",
        "outputs = hf_tokenizer.decode(outputs[0]).split('### Response:')[1].split('###')[0].strip()\n",
        "response = re.sub(chars_to_remove, '', outputs)\n",
        "\n",
        "print(f\"Therapist: {response}\")"
      ],
      "metadata": {
        "id": "5IO6Ch7_tDqe",
        "execution": {
          "iopub.status.busy": "2024-08-23T07:20:13.503860Z",
          "iopub.execute_input": "2024-08-23T07:20:13.504240Z",
          "iopub.status.idle": "2024-08-23T07:20:14.450642Z",
          "shell.execute_reply.started": "2024-08-23T07:20:13.504209Z",
          "shell.execute_reply": "2024-08-23T07:20:14.449675Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Task.3: Cloud Protype Development**\n"
      ],
      "metadata": {
        "id": "IxxNae8bZmKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T07:20:36.590121Z",
          "iopub.execute_input": "2024-08-23T07:20:36.590499Z",
          "iopub.status.idle": "2024-08-23T07:20:50.118331Z",
          "shell.execute_reply.started": "2024-08-23T07:20:36.590442Z",
          "shell.execute_reply": "2024-08-23T07:20:50.117118Z"
        },
        "trusted": true,
        "id": "IJF0Mp1eZmKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_environment():\n",
        "    if 'google.colab' in sys.modules:\n",
        "        return 'colab'\n",
        "    elif 'notebook' in sys.modules:\n",
        "        return 'jupyter'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "env = get_environment()\n",
        "print(f\"Running in: {env}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T07:22:06.224321Z",
          "iopub.execute_input": "2024-08-23T07:22:06.224851Z",
          "iopub.status.idle": "2024-08-23T07:22:06.229909Z",
          "shell.execute_reply.started": "2024-08-23T07:22:06.224818Z",
          "shell.execute_reply": "2024-08-23T07:22:06.228958Z"
        },
        "trusted": true,
        "id": "b7GSaUUpZmKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if env == 'colab':\n",
        "    ngrok_api_key = userdata.get('NGROK_API_KEY')\n",
        "elif env == 'jupyter':\n",
        "    ngrok_api_key = os.getenv('NGROK_API_KEY')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T07:27:47.765241Z",
          "iopub.execute_input": "2024-08-23T07:27:47.765935Z",
          "iopub.status.idle": "2024-08-23T07:27:47.772208Z",
          "shell.execute_reply.started": "2024-08-23T07:27:47.765894Z",
          "shell.execute_reply": "2024-08-23T07:27:47.770891Z"
        },
        "trusted": true,
        "id": "WPCkNy_UZmKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IzmONepqZmKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken ngrok_api_key\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T08:19:36.856419Z",
          "iopub.execute_input": "2024-08-23T08:19:36.856785Z",
          "iopub.status.idle": "2024-08-23T08:19:38.104117Z",
          "shell.execute_reply.started": "2024-08-23T08:19:36.856746Z",
          "shell.execute_reply": "2024-08-23T08:19:38.103031Z"
        },
        "trusted": true,
        "id": "3qGnmbexZmKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "# from flask_ngrok import run_with_ngrok\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T07:29:10.426180Z",
          "iopub.execute_input": "2024-08-23T07:29:10.426631Z",
          "iopub.status.idle": "2024-08-23T07:29:10.537577Z",
          "shell.execute_reply.started": "2024-08-23T07:29:10.426589Z",
          "shell.execute_reply": "2024-08-23T07:29:10.536785Z"
        },
        "trusted": true,
        "id": "32gnmnLHZmKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usr_msgs= [\"My daughter has been feeling really anxious about school lately, and I'm worried it's affecting her grades.\",\n",
        "\"Well, she's been complaining about having butterflies in her stomach before every test, and she's been having a hard time sleeping at night because she's worried about not doing well.\",\n",
        "\"Actually, yes. She's been really hard on herself when she makes a mistake on a test, and I think that's when the anxiety really takes over. \",\n",
        "]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T07:29:16.196697Z",
          "iopub.execute_input": "2024-08-23T07:29:16.197107Z",
          "iopub.status.idle": "2024-08-23T07:29:16.201981Z",
          "shell.execute_reply.started": "2024-08-23T07:29:16.197069Z",
          "shell.execute_reply": "2024-08-23T07:29:16.200805Z"
        },
        "trusted": true,
        "id": "r-QXaTuuZmKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(usr_msgs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T07:29:21.201849Z",
          "iopub.execute_input": "2024-08-23T07:29:21.202746Z",
          "iopub.status.idle": "2024-08-23T07:29:21.209460Z",
          "shell.execute_reply.started": "2024-08-23T07:29:21.202702Z",
          "shell.execute_reply": "2024-08-23T07:29:21.208414Z"
        },
        "trusted": true,
        "id": "qfVjg83MZmKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "\n",
        "# Set up ngrok tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:5000/\\\"\")\n",
        "\n",
        "@app.route('/')\n",
        "def predict():\n",
        "    output_list=[]\n",
        "    for um in usr_msgs:\n",
        "        inputs = hf_tokenizer(\n",
        "            [\n",
        "                prompt.format(\n",
        "                    \"You are an Expert Therapist specialized in Cognitive Behavioural Therapy (CBT). Respond to to Patient's remarks in a polite, professional, contextually meaningful and useful manner.\",  # instruction\n",
        "                    um,  # input\n",
        "                    \"\",  # output - leave this blank for generation!\n",
        "                )\n",
        "            ], return_tensors=\"pt\"\n",
        "        ).to(\"cuda\")\n",
        "        outputs = hf_model[0].generate(**inputs, max_new_tokens=64, use_cache=True)\n",
        "        chars_to_remove = re.compile('<.*?>')\n",
        "        outputs = hf_tokenizer.decode(outputs[0]).split('### Response:')[1].split('###')[0].strip()\n",
        "        outputs = re.sub(chars_to_remove, '', outputs)\n",
        "        output_list.append({\"Patient\":um, \"Therapist\":outputs})\n",
        "    print(output_list)\n",
        "    return jsonify(output_list)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-23T08:24:06.552072Z",
          "iopub.execute_input": "2024-08-23T08:24:06.552547Z",
          "iopub.status.idle": "2024-08-23T08:25:20.254944Z",
          "shell.execute_reply.started": "2024-08-23T08:24:06.552466Z",
          "shell.execute_reply": "2024-08-23T08:25:20.254037Z"
        },
        "trusted": true,
        "id": "b0SJcAN3ZmKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eYXUCt6xZmKc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}